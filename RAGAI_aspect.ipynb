{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install -qU langchain langchain_community langchain_chroma langchain-together langchain_community pypdf requests numpy pandas beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgxY1-8PIrik",
        "outputId": "b3b1f9c4-057e-4469-fee0-5bf0884943b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.5/411.5 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.10.1 requires pandas<2.2.3dev0,>=2.0, but you have pandas 2.2.3 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "transformers 4.47.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_together import ChatTogether\n",
        "\n",
        "api_key = \"INSERT API KEY\"\n",
        "\n",
        "llm = ChatTogether(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    temperature=0.5, # temperature setting here\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # top_p = 0.6, # modify here\n",
        "    api_key= api_key\n",
        ")\n",
        "\n",
        "llm_LowTemp = ChatTogether(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    temperature=0.1, # temperature setting here\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # top_p = 0.6, # modify here\n",
        "    api_key= api_key\n",
        ")\n",
        "\n",
        "llm_HighTemp = ChatTogether(\n",
        "    model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\",\n",
        "    temperature=0.8, # temperature setting here\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # top_p = 0.6, # modify here\n",
        "    api_key= api_key\n",
        ")\n"
      ],
      "metadata": {
        "id": "SsrqHc8AI2cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LinkList = [\"https://medium.com/codex/heres-why-people-avoid-buying-apple-products-56bfec1788ea\", \"https://technolotea.medium.com/apple-and-the-luxury-experience-7bc87b5dbe67\", \"https://medium.com/onlyoffice/whats-so-special-about-apple-arm-and-how-it-changes-the-rules-for-developers-1ee067a3cc6b\", \"https://medium.com/@alex.birsan/dependency-confusion-4a5d60fec610\", \"https://radioraffi.medium.com/why-apple-should-stop-saying-designed-in-california-154f8f5f383c\", \"https://iansherr.medium.com/why-your-iphone-is-designed-by-apple-in-california-but-made-in-china-d69e02ae6238\", \"https://nadrescher.medium.com/apple-or-microsoft-or-google-aaarg-7141710e5ca1\", \"https://rkegel825.medium.com/why-i-dont-use-apple-products-1cff8c3e3ea\", \"https://medium.com/macoclock/what-makes-apple-design-so-good-d430ef97c6d2\", \"https://medium.com/@marvellousniyi123/s1-why-apple-is-just-better-efficiency-e5177a9862ec\", \"https://yatharthsood.medium.com/how-disruptive-is-the-apple-m1-e6ed3dd83492\", \"https://medium.com/@joelpowell/apple-accidentally-made-the-perfect-dumb-phone-a181a9edf126\", \"Add any more links as you see fit\"]"
      ],
      "metadata": {
        "id": "JeFV8V7MNrhe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_website(url):\n",
        "    try:\n",
        "        # Send a GET request to the website\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error for bad responses\n",
        "\n",
        "        # Parse the content using BeautifulSoup\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Extract all text content from the website\n",
        "        content = soup.get_text(separator='\\n', strip=True)\n",
        "\n",
        "        return content.replace(\"\\n\", \"\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "7s4yV02l-kja"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "def SecondSentAnalysis(Link):\n",
        "  Summariser_Prompt = PromptTemplate (\n",
        "    template = \"\"\"\n",
        "      <|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "    Prompt 2:\n",
        "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
        "You are a sentiment evaluation assistant. Your task is to analyze the provided context to generate an accurate numerical value between -5 and 5.\n",
        "\n",
        " Instructions:\n",
        "\n",
        "1. Context Reference: Use the provided context for your evaluation : {context}.\n",
        "\n",
        "You must follow this Evaluation Criteria:\n",
        "\n",
        "- For Positive Ratings:\n",
        "  - Identify strong positive sentiments in the context.\n",
        "  - Assign a value from 1 to 5:\n",
        "    - 1-2:Mild positivity (e.g., slight enjoyment).\n",
        "    - 3-4:Moderate positivity (e.g., generally favorable).\n",
        "    - 5:Strong positivity (e.g., exceptional satisfaction).\n",
        "\n",
        "- For Neutral Ratings:\n",
        "  - Assess if the context has slight inclinations towards positive or negative.\n",
        "  - Assign a value from -1 to 1:\n",
        "    - -1:Slight negative inclination.\n",
        "    - 0:True neutrality.\n",
        "    - 1:Slight positive inclination.\n",
        "\n",
        "- For Negative Ratings:\n",
        "  - Look for specific expressions of dissatisfaction or negativity. Also judge the tone or sarcasm if the dissatisfaction is subtle and pick on these cues.\n",
        "  - Assign a value from -5 to -1:\n",
        "    -  -1 to -2: Mild negativity (e.g., minor issues).\n",
        "    -  -3 to -4: Moderate negativity (e.g., significant problems).\n",
        "    - -5: Strong negativity (e.g., severe dissatisfaction).\n",
        "\n",
        "You must Return only the numerical Value based on your analysis. The numerical value must be accurate.\n",
        "\n",
        "\n",
        " Additional Guidance:\n",
        "\n",
        "- Ensure your analysis considers both explicit sentiments (clear positive or negative words) and implicit sentiments (subtle hints of feelings).\n",
        "- Use clear and straightforward language in your evaluation.\n",
        "- Provide your reasoning step-by-step if necessary, but only return the final numerical value.\n",
        "\n",
        "Run this evaluation based on the provided context.\n",
        "{context}\n",
        "\n",
        "Do not return your reasoning\n",
        "\n",
        "    \"\"\"\n",
        "  )\n",
        "#  - **Explanation:** A concise explanation of the reasoning behind your sentiment classification, with references to relevant parts of the text.\n",
        "  rag_chain = Summariser_Prompt| llm_LowTemp | StrOutputParser()\n",
        "\n",
        "  generation = rag_chain.invoke({\"context\": scrape_website(Link)})\n",
        "  return generation"
      ],
      "metadata": {
        "id": "ic9M3o3BbQS8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}